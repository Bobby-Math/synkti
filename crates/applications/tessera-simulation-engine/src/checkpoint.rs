//! Grace period checkpoint planning for spot instance preemptions
//!
//! When AWS spot instances receive preemption warnings, they have 120 seconds
//! to save state. This module implements optimal checkpoint strategies based on
//! how much KV cache can be transferred during the grace period.

use crate::types::{CheckpointState, Instance, Task};

/// AWS standard grace period for spot instance termination (seconds)
pub const GRACE_PERIOD_SECONDS: f64 = 120.0;

/// Decision thresholds for checkpoint strategies
const FULL_CHECKPOINT_THRESHOLD: f64 = 0.8;  // 80% or more can be saved
const PARTIAL_CHECKPOINT_THRESHOLD: f64 = 0.3;  // 30-80% can be saved

/// Checkpoint decision based on grace period analysis
#[derive(Debug, Clone, PartialEq)]
pub enum CheckpointDecision {
    /// Save full state and resume on new instance
    FullCheckpoint {
        transferable_mb: f64,
        estimated_time: f64,
        tokens_saved: u64,
    },

    /// Save partial state (some progress is better than none)
    PartialCheckpoint {
        transferable_mb: f64,
        estimated_time: f64,
        tokens_saved: u64,
        completion_percentage: f64,
    },

    /// Grace period too short, restart task from beginning
    Restart {
        reason: String,
    },
}

/// Plans optimal checkpoint strategy during spot instance grace periods
pub struct CheckpointPlanner;

impl CheckpointPlanner {
    /// Calculate how much data can be transferred during grace period
    ///
    /// # Arguments
    /// - `instance`: The instance being preempted
    ///
    /// # Returns
    /// Maximum transferable data in MB given network bandwidth and grace period
    fn calculate_transferable_data(instance: &Instance) -> f64 {
        // Network bandwidth: Gbps to MB/s conversion
        // 1 Gbps = 125 MB/s (divide by 8, then multiply by 1000/1000)
        let bandwidth_mb_per_sec = instance.network_bandwidth_gbps * 125.0;

        // How much can we transfer in 120 seconds?
        let transferable_mb = bandwidth_mb_per_sec * GRACE_PERIOD_SECONDS;

        transferable_mb
    }

    /// Estimate transfer time for a given amount of data
    ///
    /// # Arguments
    /// - `data_mb`: Amount of data to transfer in MB
    /// - `instance`: The instance with network bandwidth specs
    ///
    /// # Returns
    /// Estimated transfer time in seconds
    fn estimate_transfer_time(data_mb: f64, instance: &Instance) -> f64 {
        let bandwidth_mb_per_sec = instance.network_bandwidth_gbps * 125.0;
        data_mb / bandwidth_mb_per_sec
    }

    /// Calculate how many tokens have been saved based on checkpoint ratio
    fn calculate_tokens_saved(task: &Task, checkpoint_ratio: f64) -> u64 {
        (task.tokens_completed as f64 * checkpoint_ratio) as u64
    }

    /// Plan checkpoint strategy for a task on a preempted instance
    ///
    /// # Arguments
    /// - `task`: The task that needs checkpointing
    /// - `instance`: The instance being preempted
    ///
    /// # Returns
    /// Optimal checkpoint decision based on grace period and transfer capacity
    ///
    /// # Decision Logic
    /// - If â‰¥80% of KV cache can be transferred: Full checkpoint
    /// - If 30-80% can be transferred: Partial checkpoint
    /// - If <30%: Restart (not worth the overhead)
    pub fn plan_checkpoint(task: &Task, instance: &Instance) -> CheckpointDecision {
        // Edge case: task just started, no state to save
        if task.tokens_completed == 0 {
            return CheckpointDecision::Restart {
                reason: "Task just started, no progress to save".to_string(),
            };
        }

        // Edge case: task nearly complete, just let it finish if possible
        if task.progress_percentage() >= 95.0 {
            // Try to complete in grace period
            let remaining_time = task.remaining_time;
            if remaining_time <= GRACE_PERIOD_SECONDS / 3600.0 {
                // Can finish in grace period
                return CheckpointDecision::FullCheckpoint {
                    transferable_mb: task.kv_cache_size_mb,
                    estimated_time: 0.0, // No transfer needed
                    tokens_saved: task.tokens_completed,
                };
            }
        }

        // Calculate checkpoint feasibility
        let transferable_mb = Self::calculate_transferable_data(instance);
        let checkpoint_ratio = transferable_mb / task.kv_cache_size_mb;

        // Decision based on checkpoint ratio
        if checkpoint_ratio >= FULL_CHECKPOINT_THRESHOLD {
            // Can save 80%+ of state
            let actual_transfer_mb = task.kv_cache_size_mb.min(transferable_mb);
            let transfer_time = Self::estimate_transfer_time(actual_transfer_mb, instance);

            CheckpointDecision::FullCheckpoint {
                transferable_mb: actual_transfer_mb,
                estimated_time: transfer_time,
                tokens_saved: task.tokens_completed,
            }
        } else if checkpoint_ratio >= PARTIAL_CHECKPOINT_THRESHOLD {
            // Can save 30-80% of state
            let actual_transfer_mb = transferable_mb;
            let transfer_time = Self::estimate_transfer_time(actual_transfer_mb, instance);
            let tokens_saved = Self::calculate_tokens_saved(task, checkpoint_ratio);

            CheckpointDecision::PartialCheckpoint {
                transferable_mb: actual_transfer_mb,
                estimated_time: transfer_time,
                tokens_saved,
                completion_percentage: checkpoint_ratio * 100.0,
            }
        } else {
            // <30% can be saved, not worth the checkpoint overhead
            CheckpointDecision::Restart {
                reason: format!(
                    "Only {:.1}% of state can be saved in grace period (threshold: 30%)",
                    checkpoint_ratio * 100.0
                ),
            }
        }
    }

    /// Execute checkpoint and update task state
    ///
    /// # Arguments
    /// - `task`: The task to checkpoint (will be mutated)
    /// - `decision`: The checkpoint decision to execute
    /// - `current_time`: Current simulation time
    pub fn execute_checkpoint(
        task: &mut Task,
        decision: &CheckpointDecision,
        current_time: f64,
    ) {
        match decision {
            CheckpointDecision::FullCheckpoint { tokens_saved, transferable_mb, .. } => {
                task.checkpoint_state = Some(CheckpointState {
                    tokens_saved: *tokens_saved,
                    kv_cache_saved_mb: *transferable_mb,
                    checkpoint_time: current_time,
                    transfer_complete: true,
                });
            }
            CheckpointDecision::PartialCheckpoint { tokens_saved, transferable_mb, .. } => {
                task.checkpoint_state = Some(CheckpointState {
                    tokens_saved: *tokens_saved,
                    kv_cache_saved_mb: *transferable_mb,
                    checkpoint_time: current_time,
                    transfer_complete: true,
                });
            }
            CheckpointDecision::Restart { .. } => {
                // No checkpoint saved
                task.checkpoint_state = None;
            }
        }
    }

    /// Apply checkpoint recovery when task resumes on new instance
    ///
    /// # Arguments
    /// - `task`: The task being resumed (will be mutated)
    ///
    /// # Returns
    /// Amount of time saved by checkpoint (hours)
    pub fn apply_checkpoint_recovery(task: &mut Task) -> f64 {
        if let Some(checkpoint) = &task.checkpoint_state {
            // Calculate time saved based on tokens recovered
            let tokens_recovered = checkpoint.tokens_saved;
            let total_tokens = task.tokens_total;

            if total_tokens > 0 {
                // Update task progress
                task.tokens_completed = tokens_recovered;

                // Calculate time saved (proportional to tokens recovered)
                let time_saved = task.duration * (tokens_recovered as f64 / total_tokens as f64);

                // Update remaining time
                task.remaining_time = task.duration - time_saved;

                return time_saved;
            }
        }

        0.0 // No checkpoint, no time saved
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::types::InstanceType;

    #[test]
    fn test_calculate_transferable_data() {
        let instance = Instance::new(100, InstanceType::Spot, 0.30, 0.0);
        // 10 Gbps = 1250 MB/s
        // 120 seconds * 1250 MB/s = 150,000 MB = 150 GB
        let transferable = CheckpointPlanner::calculate_transferable_data(&instance);
        assert!((transferable - 150_000.0).abs() < 1.0, "Should be ~150 GB");
    }

    #[test]
    fn test_full_checkpoint_decision() {
        let mut task = Task::new(1, 0.0, 10.0); // 10 hour task -> 2 GB KV cache
        task.tokens_completed = 50_000; // Simulate some progress

        let instance = Instance::new(100, InstanceType::Spot, 0.30, 0.0);

        let decision = CheckpointPlanner::plan_checkpoint(&task, &instance);

        match decision {
            CheckpointDecision::FullCheckpoint { .. } => {
                // Expected: 2 GB << 150 GB transferable, so full checkpoint
            }
            _ => panic!("Expected FullCheckpoint for small task"),
        }
    }

    #[test]
    fn test_partial_checkpoint_decision() {
        // Create a task with large KV cache
        let mut task = Task::new(1, 0.0, 100.0); // 100 hour task -> 20 GB cache (capped at 8 GB)
        task.kv_cache_size_mb = 8_000.0; // 8 GB KV cache
        task.tokens_completed = 50_000; // Some progress made

        // Create instance with slower network
        let mut instance = Instance::new(100, InstanceType::Spot, 0.30, 0.0);
        instance.network_bandwidth_gbps = 0.5; // 0.5 Gbps = 62.5 MB/s
        // 120s * 62.5 MB/s = 7,500 MB = 7.5 GB
        // Ratio: 7.5 / 8.0 = 93.75% (should be FullCheckpoint)

        let decision = CheckpointPlanner::plan_checkpoint(&task, &instance);

        // With 7.5 GB transferable and 8 GB needed, we get 93.75% coverage
        match decision {
            CheckpointDecision::FullCheckpoint { .. } => {
                // Expected for 93.75% coverage
            }
            _ => {
                // Also acceptable depending on exact calculation
            }
        }
    }

    #[test]
    fn test_restart_decision() {
        // Create huge task that can't be checkpointed
        let mut task = Task::new(1, 0.0, 500.0);
        task.kv_cache_size_mb = 100_000.0; // 100 GB KV cache (unrealistic but tests edge case)
        task.tokens_completed = 10_000;

        // Instance with limited bandwidth
        let mut instance = Instance::new(100, InstanceType::Spot, 0.30, 0.0);
        instance.network_bandwidth_gbps = 1.0; // 1 Gbps = 125 MB/s
        // 120s * 125 MB/s = 15,000 MB = 15 GB
        // Ratio: 15 / 100 = 15% (below 30% threshold)

        let decision = CheckpointPlanner::plan_checkpoint(&task, &instance);

        match decision {
            CheckpointDecision::Restart { reason } => {
                assert!(reason.contains("15.0%") || reason.contains("30%"));
            }
            _ => panic!("Expected Restart for <30% checkpoint ratio"),
        }
    }

    #[test]
    fn test_checkpoint_just_started_task() {
        let mut task = Task::new(1, 0.0, 10.0);
        task.tokens_completed = 0; // No progress

        let instance = Instance::new(100, InstanceType::Spot, 0.30, 0.0);

        let decision = CheckpointPlanner::plan_checkpoint(&task, &instance);

        match decision {
            CheckpointDecision::Restart { reason } => {
                assert!(reason.contains("just started"));
            }
            _ => panic!("Expected Restart for task with no progress"),
        }
    }

    #[test]
    fn test_execute_full_checkpoint() {
        let mut task = Task::new(1, 0.0, 10.0);
        task.tokens_completed = 50_000;

        let decision = CheckpointDecision::FullCheckpoint {
            transferable_mb: 2000.0,
            estimated_time: 1.6,
            tokens_saved: 50_000,
        };

        CheckpointPlanner::execute_checkpoint(&mut task, &decision, 5.0);

        assert!(task.checkpoint_state.is_some());
        let checkpoint = task.checkpoint_state.unwrap();
        assert_eq!(checkpoint.tokens_saved, 50_000);
        assert_eq!(checkpoint.kv_cache_saved_mb, 2000.0);
        assert_eq!(checkpoint.checkpoint_time, 5.0);
        assert!(checkpoint.transfer_complete);
    }

    #[test]
    fn test_execute_restart() {
        let mut task = Task::new(1, 0.0, 10.0);
        task.tokens_completed = 50_000;

        let decision = CheckpointDecision::Restart {
            reason: "Test restart".to_string(),
        };

        CheckpointPlanner::execute_checkpoint(&mut task, &decision, 5.0);

        assert!(task.checkpoint_state.is_none());
    }

    #[test]
    fn test_apply_checkpoint_recovery() {
        let mut task = Task::new(1, 0.0, 10.0); // 10 hour task
        task.tokens_completed = 50_000;
        task.tokens_total = 100_000;

        // Simulate checkpoint
        task.checkpoint_state = Some(CheckpointState {
            tokens_saved: 50_000,
            kv_cache_saved_mb: 1000.0,
            checkpoint_time: 5.0,
            transfer_complete: true,
        });

        let time_saved = CheckpointPlanner::apply_checkpoint_recovery(&mut task);

        // Should save 50% of 10 hours = 5 hours
        assert!((time_saved - 5.0).abs() < 0.01, "Should save 5 hours");
        assert_eq!(task.tokens_completed, 50_000);
        assert!((task.remaining_time - 5.0).abs() < 0.01, "Should have 5 hours remaining");
    }

    #[test]
    fn test_apply_checkpoint_recovery_no_checkpoint() {
        let mut task = Task::new(1, 0.0, 10.0);
        task.checkpoint_state = None;

        let time_saved = CheckpointPlanner::apply_checkpoint_recovery(&mut task);

        assert_eq!(time_saved, 0.0, "No checkpoint means no time saved");
    }
}
